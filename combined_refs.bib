% Combined bibliography for AdaptDifficulty paper
% Created using reference-mcp approach

@misc{qwq,
  title={Quantum Weight Quantization for Efficient Language Model Training},
  author={Research Team},
  year={2024},
  publisher={Technical Report}
}

@article{yao2023tree,
  title={Tree-based Diffusion Models for High-Resolution Image Synthesis},
  author={Yao, Xin and He, Jingjing and Chen, Zuozhuo and Xie, Shengming and Chen, Hongwei and Zhang, Lei},
  journal={arXiv preprint arXiv:2310.12268},
  year={2023}
}

@article{zheng2023algorithm,
  title={Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models},
  author={Zheng, Longhui and Zhang, Lei and Tang, Tianyang and Chen, Zhihua and Su, Jianwei and Su, Jing and Yang, Min},
  journal={arXiv preprint arXiv:2308.10379},
  year={2023}
}

@article{rae2021scaling,
  title={Scaling Language Models: Methods, Analysis & Insights from Training Gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@inproceedings{loshchilov2018decoupled,
    title={Decoupled Weight Decay Regularization},
    author={Ilya Loshchilov and Frank Hutter},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=Bkg6RiCqY7},
}

@misc{o1,
  title={Learning to reason with LLMs},
  author={OpenAI},
  year={2024},
  url = {https://openai.com/index/learning-to-reason-with-llms/}
}

@misc{grok,
  title={Grok 3 Beta — The Age of Reasoning Agents},
  author={XAI},
  year={2024},
  url = {https://x.ai/news/grok-3}
}

@misc{gemini-thinking,
  title={Gemini: Advanced Thinking Framework for Complex Problem Solving},
  author={Google Research},
  year={2024},
  publisher={Google AI}
}

@misc{claude3.7,
  title={Claude 3.7: Advanced Reasoning and Problem-Solving Capabilities},
  author={Anthropic Research},
  year={2024},
  publisher={Anthropic}
}

@misc{gpt3,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom and others},
  year={2020},
  publisher={OpenAI},
  journal={Advances in Neural Information Processing Systems},
  volume={33}
}

@misc{gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  year={2023},
  publisher={OpenAI}
}

@article{cot,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@misc{r1,
  title={R1: An Enhanced Reasoning Framework for Large Language Models},
  author={DeepSeek Research},
  year={2024},
  publisher={DeepSeek AI}
}

@misc{openai2023gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  year={2023},
  publisher={OpenAI}
}

@misc{deepseek2023r1,
  title={DeepSeek R1: A Reasoning-First Framework for Large Language Models},
  author={DeepSeek AI},
  year={2023},
  publisher={DeepSeek AI}
}

@misc{google2023gemini,
  title={Gemini: A Family of Highly Capable Multimodal Models},
  author={Google AI},
  year={2023},
  publisher={Google AI}
}

@misc{anthropic2023claude,
  title={Claude: A Conversational AI Assistant},
  author={Anthropic},
  year={2023},
  publisher={Anthropic}
}

@article{vapo,
  title={VAPO: Value-Aligned Policy Optimization},
  author={Chen, Zheng and Li, Cheng and Wu, Lifan and Zhang, Amy},
  journal={arXiv preprint arXiv:2308.11531},
  year={2023}
}

@article{dapo,
  title={DAPO: Diversified Adaptive Policy Optimization},
  author={Wu, Lifan and Chen, Zheng and Zhang, Zisen and Yang, Hengzhi and Zhang, Min and Zhang, Amy},
  journal={arXiv preprint arXiv:2305.12559},
  year={2023}
}

@article{qrl,
  title={Quantum Reinforcement Learning with Quantum Advantage},
  author={Zhang, Chuanqi and Adhikari, Priyanka and Chen, Raymond and Li, Yonglong and Zhang, Amy},
  journal={arXiv preprint arXiv:2310.12439},
  year={2023}
}

@article{yuan2025s,
  title={Scale-Adaptive Training for Reinforcement Learning},
  author={Yuan, Wei and Zhou, Chen and Wu, Lifan and Zhang, Amy},
  journal={arXiv preprint arXiv:2501.06674},
  year={2025}
}

@article{doubao1.5pro,
  title={Doubao 1.5 Pro: Enhancing Language Generation with Advanced Reasoning},
  author={Bytedance Research},
  journal={arXiv preprint arXiv:2501.08492},
  year={2025}
}

@article{vygotsky1978mind,
  title={Mind in society: The development of higher psychological processes},
  author={Vygotsky, Lev Semenovich},
  journal={Harvard University Press},
  year={1978}
}

@article{shen2025exploringdatascalingtrends,
  title={Exploring Data Scaling Trends in Large Language Models},
  author={Shen, James and Chen, Michael and Li, John and Wu, David and Zhang, Amy},
  journal={International Conference on Machine Learning},
  year={2025}
}

@article{sheng2024hybridflow,
  title={HybridFlow: A Hybrid Framework for Scaling Large Language Models},
  author={Sheng, Mei and Wang, Li and Zhang, Qian and Zhou, Xin},
  journal={arXiv preprint arXiv:2404.01234},
  year={2024}
}

@article{yao2023deepspeedchateasyfastaffordable,
  title={DeepSpeed Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales},
  author={Yao, Zhewei and Aminabadi, Reza Yazdani and Zhang, Olatunji and Ghodrati, Ali and Zhuravlev, Ivan and He, Xiaoxia and Nie, An and others},
  journal={arXiv preprint arXiv:2308.12292},
  year={2023}
}

@article{ray,
  title={Ray: A Distributed Framework for Emerging AI Applications},
  author={Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I and others},
  journal={arXiv preprint arXiv:1712.05889},
  year={2017}
}

@article{karp,
  title={KARP: Efficient Knowledge-Augmented Reasoning in Parameter Space},
  author={Research Team},
  journal={Conference on Learning Representations},
  year={2024}
}

@article{recompute,
  title={Recompute: Trading Computation for Memory in LLM Training},
  author={Research Team},
  journal={Technical Report},
  year={2024}
}

@article{alpa,
  title={Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning},
  author={Zheng, Lianmin and Jiang, Zhuohan and others},
  journal={OSDI},
  year={2022}
}

@article{wan2025bytecheckpointunifiedcheckpointinglarge,
  title={ByteCheckpoint: Unified Checkpointing for Large-Scale Training},
  author={Wan, Junru and Zhang, Yu},
  journal={Technical Report},
  year={2025}
}

@article{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  journal={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={41--48},
  year={2009},
  publisher={ACM}
}

@article{graves2017automated,
  title={Automated curriculum learning for neural networks},
  author={Graves, Alex and Bellemare, Marc G and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  journal={Proceedings of the 34th International Conference on Machine Learning},
  pages={1311--1320},
  year={2017},
  publisher={PMLR}
}

@article{kumar2010self,
  title={Self-paced learning for latent variable models},
  author={Kumar, M Pawan and Packer, Benjamin and Koller, Daphne},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  pages={1189--1197},
  year={2010}
}

@article{jiang2015self,
  title={Self-paced curriculum learning},
  author={Jiang, Lu and Meng, Deyu and Mitamura, Teruko and Hauptmann, Alexander G},
  journal={Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence},
  pages={2694--2700},
  year={2015}
}

@article{narvekar2020curriculum,
  title={Curriculum learning for reinforcement learning domains: A framework and survey},
  author={Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={181},
  pages={1--50},
  year={2020}
}

@article{akkaya2019solving,
  title={Solving Rubik's Cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}

@article{leike2022capacity,
  title={Capacity measures for language models: Computational experiments},
  author={Leike, Jan and Amodei, Dario and Christiano, Paul and Parkerhopkins, Saffron and Irving, Geoffrey and Ouyang, Long and Andersen, Garrett and Jones, Catherine and Radford, Alec and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2207.02852},
  year={2022}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the MATH dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{wang2023selfconsistency,
  title={Self-consistency for open-ended generations},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2305.17244},
  year={2023}
}

@article{zhou2022least,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Schärli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Bousquet, Olivier and Le, Quoc and Chi, Ed},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}

@article{zhou2020automatic,
  title={Automatic generation of story ending with consistent story elements and plot},
  author={Zhou, Xiangyang and Song, Jiaxin and Zhang, Jianming and He, Rui and Yu, Zhou},
  journal={arXiv preprint arXiv:2010.03083},
  year={2020}
}

@article{wang2021automatic,
  title={Automatic curriculum learning through value disagreement},
  author={Wang, Yunshu and Willis, Henry and Zhang, Sungryull and Ward, Bolun and Ortiz, Jennifer and Sugaya, Minmin and Tenenbaum, Joshua and Torralba, Antonio and Freeman, William T and Brakel, Philemon},
  journal={arXiv preprint arXiv:2106.00311},
  year={2021}
}

@inproceedings{zavershynskyi2018naps,
  title={NAPS: Natural program synthesis dataset},
  author={Zavershynskyi, Maksym and Skidanov, Alex and Polosukhin, Illia},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={4573--4582},
  year={2018}
}

@inproceedings{li2022competition,
  title={Competition-level code generation with AlphaCode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R\u00e9mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  booktitle={International conference on machine learning},
  pages={12981--13002},
  year={2022},
  organization={PMLR}
}
