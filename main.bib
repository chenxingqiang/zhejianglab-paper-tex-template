@inproceedings{
    loshchilov2018decoupled,
    title={Decoupled Weight Decay Regularization},
    author={Ilya Loshchilov and Frank Hutter},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=Bkg6RiCqY7},
}

@misc{o1,
  title={Learning to reason with LLMs},
  author={OpenAI},
  year={2024},
  url = {https://openai.com/index/learning-to-reason-with-llms/}
}

@misc{grok,
  title={Grok 3 Beta — The Age of Reasoning Agents},
  author={XAI},
  year={2024},
  url = {https://x.ai/news/grok-3}
}

@misc{gemini-thinking,
  title={Gemini 2.0 Flash Thinking},
  author={Google DeepMind},
  year={2024},
  url = {https://deepmind.google/technologies/gemini/flash-thinking/}
}

@misc{qwq,
  title={QwQ-32B: Embracing the Power of Reinforcement Learning},
  author={Qwen},
  year={2024},
  url = {https://qwenlm.github.io/blog/qwq-32b/}
}

@article{cot,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{k1.5,
  title={Kimi k1. 5: Scaling reinforcement learning with llms},
  author={Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others},
  journal={arXiv preprint arXiv:2501.12599},
  year={2025}
}

@article{gpt4,
  title={{GPT4} technical report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{gandhi2025cognitive,
  title={Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs},
  author={Gandhi, Kanishk and Chakravarthy, Ayush and Singh, Anikait and Lile, Nathan and Goodman, Noah D},
  journal={arXiv preprint arXiv:2503.01307},
  year={2025}
}
@misc{claude35sonnet,
  title = {Claude 3.5 Sonnet},
  author = {Anthropic},
  url = {https://www.anthropic.com/news/claude-3-5-sonnet},
  year={2024}
}
@article{wang2025thoughts,
  title={Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs},
  author={Wang, Yue and Liu, Qiuzhi and Xu, Jiahao and Liang, Tian and Chen, Xingyu and He, Zhiwei and Song, Linfeng and Yu, Dian and Li, Juntao and Zhang, Zhuosheng and others},
  journal={arXiv preprint arXiv:2501.18585},
  year={2025}
}
@article{cuadron2025danger,
  title={The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks},
  author={Cuadron, Alejandro and Li, Dacheng and Ma, Wenjie and Wang, Xingyao and Wang, Yichuan and Zhuang, Siyuan and Liu, Shu and Schroeder, Luis Gaspar and Xia, Tian and Mao, Huanzhi and others},
  journal={arXiv preprint arXiv:2502.08235},
  year={2025}
}
@inproceedings{NEURIPS2022_b1efde53,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27730--27744},
 publisher = {Curran Associates, Inc.},
 title = {Training language models to follow instructions with human feedback},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Zhang, Mingchuan and Li, YK and Wu, Y and Guo, Daya},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}
@article{alphazero,
  author       = {David Silver and
                  Thomas Hubert and
                  Julian Schrittwieser and
                  Ioannis Antonoglou and
                  Matthew Lai and
                  Arthur Guez and
                  Marc Lanctot and
                  Laurent Sifre and
                  Dharshan Kumaran and
                  Thore Graepel and
                  Timothy P. Lillicrap and
                  Karen Simonyan and
                  Demis Hassabis},
  title        = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
                  Learning Algorithm},
  journal      = {CoRR},
  volume       = {abs/1712.01815},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.01815},
  eprinttype    = {arXiv},
  eprint       = {1712.01815},
  timestamp    = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-01815.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@misc{kl,
  title={Approximating kl divergence},
  author={John Schulman},
  year={2020},
  url = {http://joschu.net/blog/kl-approx.html}
}

@article{le2022coderl,
  title={Coderl: Mastering code generation through pretrained models and deep reinforcement learning},
  author={Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven Chu Hong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21314--21328},
  year={2022}
}

@article{trinh2024solving,
  title={Solving olympiad geometry without human demonstrations},
  author={Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang},
  journal={Nature},
  volume={625},
  number={7995},
  pages={476--482},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{sheng2024hybridflow,
  title={Hybridflow: A flexible and efficient rlhf framework},
  author={Sheng, Guangming and Zhang, Chi and Ye, Zilingfeng and Wu, Xibin and Zhang, Wang and Zhang, Ru and Peng, Yanghua and Lin, Haibin and Wu, Chuan},
  journal={arXiv preprint arXiv:2409.19256},
  year={2024}
}

@misc{amodei2016concreteproblemsaisafety,
      title={Concrete Problems in AI Safety}, 
      author={Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Mané},
      year={2016},
      eprint={1606.06565},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1606.06565}, 
}

@misc{everitt2017reinforcementlearningcorruptedreward,
      title={Reinforcement Learning with a Corrupted Reward Channel}, 
      author={Tom Everitt and Victoria Krakovna and Laurent Orseau and Marcus Hutter and Shane Legg},
      year={2017},
      eprint={1705.08417},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1705.08417}, 
}

@misc{everitt2021rewardtamperingproblemssolutions,
      title={Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective}, 
      author={Tom Everitt and Marcus Hutter and Ramana Kumar and Victoria Krakovna},
      year={2021},
      eprint={1908.04734},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1908.04734}, 
}

@misc{google2020specialgaming,
  title={Specification gaming: the flip side of AI ingenuity},
  author={Victoria Krakovna and Jonathan Uesato and Vladimir Mikulik and Matthew Rahtz and Tom Everitt and Ramana Kumar and Zac Kenton and Jan Leike and Shane Legg},
  year={2020},
  url = {https://deepmind.google/discover/blog/specification-gaming-the-flip-side-of-ai-ingenuity/}
}

@misc{gao2022scalinglawsrewardmodel,
      title={Scaling Laws for Reward Model Overoptimization}, 
      author={Leo Gao and John Schulman and Jacob Hilton},
      year={2022},
      eprint={2210.10760},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.10760}, 
}

@misc{langosco2023goalmisgeneralizationdeepreinforcement,
      title={Goal Misgeneralization in Deep Reinforcement Learning}, 
      author={Lauro Langosco and Jack Koch and Lee Sharkey and Jacob Pfau and Laurent Orseau and David Krueger},
      year={2023},
      eprint={2105.14111},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2105.14111}, 
}

@misc{pan2022effectsrewardmisspecificationmapping,
      title={The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models}, 
      author={Alexander Pan and Kush Bhatia and Jacob Steinhardt},
      year={2022},
      eprint={2201.03544},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2201.03544}, 
}

@article{weng2024rewardhack,
  title   = "Reward Hacking in Reinforcement Learning.",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2024",
  month   = "Nov",
  url     = "https://lilianweng.github.io/posts/2024-11-28-reward-hacking/"
}


@misc{polu2020generativelanguagemodelingautomated,
      title={Generative Language Modeling for Automated Theorem Proving}, 
      author={Stanislas Polu and Ilya Sutskever},
      year={2020},
      eprint={2009.03393},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2009.03393}, 
}

@misc{gehring2025rlefgroundingcodellms,
      title={RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning}, 
      author={Jonas Gehring and Kunhao Zheng and Jade Copet and Vegard Mella and Quentin Carbonneaux and Taco Cohen and Gabriel Synnaeve},
      year={2025},
      eprint={2410.02089},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.02089}, 
}

@misc{shinn2023reflexionlanguageagentsverbal,
      title={Reflexion: Language Agents with Verbal Reinforcement Learning}, 
      author={Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2303.11366},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2303.11366}, 
}

@misc{chen2023teachinglargelanguagemodels,
      title={Teaching Large Language Models to Self-Debug}, 
      author={Xinyun Chen and Maxwell Lin and Nathanael Schärli and Denny Zhou},
      year={2023},
      eprint={2304.05128},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.05128}, 
}

@misc{google2024alphageometry,
  title={AlphaGeometry: An Olympiad-level AI system for geometry},
  author={Trieu Trinh and Thang Luong},
  year={2024},
  url = {https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/}
}

@misc{google2024alphaproofandalphageometry,
  title={AI achieves silver-medal standard solving International Mathematical Olympiad problems},
  author={AlphaProof and AlphaGeometry Teams},
  year={2024},
  url = {https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/}
}

@misc{schulman2018highdimensionalcontinuouscontrolusing,
      title={High-Dimensional Continuous Control Using Generalized Advantage Estimation}, 
      author={John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
      year={2018},
      eprint={1506.02438},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1506.02438}, 
}

@article{gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{dsv3,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{rendarl,
  title={An Empirical Study on Eliciting and Improving R1-like Reasoning Models},
  author={Chen, Zhipeng and Min, Yingqian and Zhang, Beichen and Chen, Jie and Jiang, Jinhao and Cheng, Daixuan and Zhao, Wayne Xin and Liu, Zheng and Miao, Xu and Lu, Yang and others},
  journal={arXiv preprint arXiv:2503.04548},
  year={2025}
}
@misc{OpenReasonerZero2025,
  title={Open-Reasoner-Zero: An Open Source Approach to Scaling Reinforcement Learning on the Base Model},
  author={Jingcheng Hu and Yinmin Zhang and Qi Han and Daxin Jiang and Xiangyu Zhang, Heung-Yeung Shum},
  year={2025},
  howpublished={\url{https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero}},
}

@article{hu2025reinforce++,
  title={REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models},
  author={Hu, Jian},
  journal={arXiv preprint arXiv:2501.03262},
  year={2025}
}

@article{cui2025process,
  title={Process reinforcement through implicit rewards},
  author={Cui, Ganqu and Yuan, Lifan and Wang, Zefan and Wang, Hanbin and Li, Wendi and He, Bingxiang and Fan, Yuchen and Yu, Tianyu and Xu, Qixin and Chen, Weize and others},
  journal={arXiv preprint arXiv:2502.01456},
  year={2025}
}

@article{lee2024token,
  title={Token-Supervised Value Models for Enhancing Mathematical Reasoning Capabilities of Large Language Models},
  author={Lee, Jung Hyun and Yang, June Yong and Heo, Byeongho and Han, Dongyoon and Yoo, Kang Min},
  journal={arXiv preprint arXiv:2407.12863},
  year={2024}
}

@article{kazemnejad2024vineppo,
  title={Vineppo: Unlocking rl potential for llm reasoning through refined credit assignment},
  author={Kazemnejad, Amirhossein and Aghajohari, Milad and Portelance, Eva and Sordoni, Alessandro and Reddy, Siva and Courville, Aaron and Roux, Nicolas Le},
  journal={arXiv preprint arXiv:2410.01679},
  year={2024}
}

@article{yuan2025s,
  title={What's Behind PPO's Collapse in Long-CoT? Value Optimization Holds the Secret},
  author={Yuan, Yufeng and Yue, Yu and Zhu, Ruofei and Fan, Tiantian and Yan, Lin},
  journal={arXiv preprint arXiv:2503.01491},
  year={2025}
}

@misc{qrl,
      title={A Unified Pairwise Framework for RLHF: Bridging Generative Reward Modeling and Policy Optimization}, 
      author={Wenyuan Xu and Xiaochen Zuo and Chao Xin and Yu Yue and Lin Yan and Yonghui Wu},
      year={2025},
      eprint={2504.04950},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2504.04950}, 
}

@misc{vapo,
      title={VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks}, 
      author={Yu Yue and Yufeng Yuan and Qiying Yu and Xiaochen Zuo and Ruofei Zhu and Wenyuan Xu and Jiaze Chen and Chengyi Wang and TianTian Fan and Zhengyin Du and Xiangpeng Wei and Xiangyu Yu and Gaohong Liu and Juncai Liu and Lingjun Liu and Haibin Lin and Zhiqi Lin and Bole Ma and Chi Zhang and Mofan Zhang and Wang Zhang and Hang Zhu and Ru Zhang and Xin Liu and Mingxuan Wang and Yonghui Wu and Lin Yan},
      year={2025},
      eprint={2504.05118},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.05118}, 
}

@misc{dapo,
      title={DAPO: An Open-Source LLM Reinforcement Learning System at Scale}, 
      author={Qiying Yu and Zheng Zhang and Ruofei Zhu and Yufeng Yuan and Xiaochen Zuo and Yu Yue and Tiantian Fan and Gaohong Liu and Lingjun Liu and Xin Liu and Haibin Lin and Zhiqi Lin and Bole Ma and Guangming Sheng and Yuxuan Tong and Chi Zhang and Mofan Zhang and Wang Zhang and Hang Zhu and Jinhua Zhu and Jiaze Chen and Jiangjie Chen and Chengyi Wang and Hongli Yu and Weinan Dai and Yuxuan Song and Xiangpeng Wei and Hao Zhou and Jingjing Liu and Wei-Ying Ma and Ya-Qin Zhang and Lin Yan and Mu Qiao and Yonghui Wu and Mingxuan Wang},
      year={2025},
      eprint={2503.14476},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2503.14476}, 
}


@misc{o3,
  title={Learning to reason with LLMs},
  author={OpenAI},
  year={2025},
  url = {https://openai.com/index/openai-o3-mini/}
}

@misc{r1,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}

@misc{gemini2.5,
  title={Gemini 2.5: Our most intelligent AI model},
  author={Google DeepMind},
  year={2025},
  url = {https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/}
}

@misc{claude3.7,
  title={Claude 3.7 Sonnet and Claude Code},
  author={Anthropic},
  year={2025},
  url = {https://www.anthropic.com/claude/sonnet}
}

@misc{doubao1.5pro,
  title={Doubao-1.5-pro},
  author={ByteDance},
  year={2025},
  url = {https://team.doubao.com/en/special/doubao_1_5_pro}
}




@misc{xu25rlhf,
      title={A Unified Pairwise Framework for RLHF: Bridging Generative Reward Modeling and Policy Optimization}, 
      author={Wenyuan Xu and Xiaochen Zuo and Chao Xin and Yu Yue and Lin Yan and Yonghui Wu},
      year={2025},
      eprint={2504.04950},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2504.04950}, 
}


# system reference

@article{ray,
  author       = {Philipp Moritz and
                  Robert Nishihara and
                  Stephanie Wang and
                  Alexey Tumanov and
                  Richard Liaw and
                  Eric Liang and
                  William Paul and
                  Michael I. Jordan and
                  Ion Stoica},
  title        = {Ray: {A} Distributed Framework for Emerging {AI} Applications},
  journal      = {CoRR},
  volume       = {abs/1712.05889},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.05889},
  eprinttype    = {arXiv},
  eprint       = {1712.05889},
  timestamp    = {Mon, 13 Aug 2018 16:46:39 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-05889.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{yao2023deepspeedchateasyfastaffordable,
      title={DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales}, 
      author={Zhewei Yao and Reza Yazdani Aminabadi and Olatunji Ruwase and Samyam Rajbhandari and Xiaoxia Wu and Ammar Ahmad Awan and Jeff Rasley and Minjia Zhang and Conglong Li and Connor Holmes and Zhongzhu Zhou and Michael Wyatt and Molly Smith and Lev Kurilenko and Heyang Qin and Masahiro Tanaka and Shuai Che and Shuaiwen Leon Song and Yuxiong He},
      year={2023},
      eprint={2308.01320},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2308.01320}, 
}

@misc{wan2025bytecheckpointunifiedcheckpointinglarge,
      title={ByteCheckpoint: A Unified Checkpointing System for Large Foundation Model Development}, 
      author={Borui Wan and Mingji Han and Yiyao Sheng and Yanghua Peng and Haibin Lin and Mofan Zhang and Zhichao Lai and Menghan Yu and Junda Zhang and Zuquan Song and Xin Liu and Chuan Wu},
      year={2025},
      eprint={2407.20143},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.20143}, 
}

@article{recompute,
  title={Training deep nets with sublinear memory cost},
  author={Chen, Tianqi and Xu, Bing and Zhang, Chiyuan and Guestrin, Carlos},
  journal={arXiv preprint arXiv:1604.06174},
  year={2016}
}

@inproceedings{alpa,
  title={Alpa: Automating inter-and $\{$Intra-Operator$\}$ parallelism for distributed deep learning},
  author={Zheng, Lianmin and Li, Zhuohan and Zhang, Hao and Zhuang, Yonghao and Chen, Zhifeng and Huang, Yanping and Wang, Yida and Xu, Yuanzhong and Zhuo, Danyang and Xing, Eric P and others},
  booktitle={16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
  pages={559--578},
  year={2022}
}

@book{karp,
  title={The differencing method of set partitioning},
  author={Karmarkar, Narendra and Karp, Richard M},
  year={1982},
  publisher={Computer Science Division (EECS), University of California Berkeley}
}

@misc{shen2025exploringdatascalingtrends,
      title={Exploring Data Scaling Trends and Effects in Reinforcement Learning from Human Feedback}, 
      author={Wei Shen and Guanlin Liu and Zheng Wu and Ruofei Zhu and Qingping Yang and Chao Xin and Yu Yue and Lin Yan},
      year={2025},
      eprint={2503.22230},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2503.22230}, 
}